{"cells": [{"metadata": {"collapsed": true, "id": "ef7b570a-2105-4d47-8574-d12149365b31"}, "cell_type": "markdown", "source": "# Using Models and deployments\nIn this notebook, we use the WML client API to:\n- List the models in a deployment space\n- List the available deployments\n- Score using the `AutoAI Churn Deployment` deployed model\n- Promote and deploy the `AutoAI Price Estimate Model` model\n- Score records using the `AutoAI Price Estimate Model` deployed model\n- Create, save, deploy a model using sklearn, then score some data with it.\n- List spaces\n- List pipelines\n- List experiments\n- List runtimes\n"}, {"metadata": {"id": "1defe70b-8284-4438-842f-7154e0029b76"}, "cell_type": "markdown", "source": "## Pre-requisites\nIt is assumes that you completed the previous part of the lab:\n- Create and deploy an AutoAI churn model \n- Create an AutoAI price prediction model\n"}, {"metadata": {"id": "eb4634ad-4fe8-4322-8766-b7fb2a5d3438"}, "cell_type": "markdown", "source": "## Watson Machine Learning APIs\nSee documentation: \n- Client API: https://wml-api-pyclient-dev-v4.mybluemix.net/\n- REST API V2: https://cloud.ibm.com/apidocs/watson-data-api-cpd\n- REST API V4: https://watson-ml-v4-api.mybluemix.net/"}, {"metadata": {"id": "d0d2c229-7534-4088-9af1-c32c3df3609d"}, "cell_type": "markdown", "source": "## Insert your WML service credentials below\nInsert your username and password in the credential field"}, {"metadata": {"id": "c53e938f-a053-41ea-a958-c394d8b761fc"}, "cell_type": "code", "source": "import os, json, requests\n# These are you credentials. You may want to remove them before sharing this notebook\ncredentials_url = os.getenv('RUNTIME_ENV_APSX_URL')\ncredentials_username = \"username\"\ncredentials_password = \"password\"", "execution_count": null, "outputs": []}, {"metadata": {"id": "24542410-61da-4122-bed8-c809518421be"}, "cell_type": "markdown", "source": "## Create a client connection"}, {"metadata": {"id": "e0fc1349-350b-4192-b285-5cc3efbedd16"}, "cell_type": "code", "source": "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n\nwml_credentials = {\n    \"instance_id\": \"openshift\",\n    \"url\": credentials_url,\n    \"username\":credentials_username,\n    \"password\": credentials_password,\n    \"version\": \"2.5.0\"\n}\n\nclient = WatsonMachineLearningAP1Client(wml_credentials)\nprint(\"Client version: \" + client.version)", "execution_count": null, "outputs": []}, {"metadata": {"id": "bb4c05a2-f8a9-4e34-ab94-be87431fa61e"}, "cell_type": "code", "source": "user_id = os.getenv('USER_ID')\nproject_id = os.getenv('PROJECT_ID')\nproject_name = os.getenv('PROJECT_NAME')\naccessToken = os.getenv('USER_ACCESS_TOKEN')\nservice_instance_url = client.service_instance.get_url()\nmlInstanceGuid = client.service_instance.get_instance_id()\n", "execution_count": null, "outputs": []}, {"metadata": {"id": "fa0ddcc3-e880-4b1a-9aec-b5462d5515ac"}, "cell_type": "markdown", "source": "### Find the project deployment space"}, {"metadata": {"id": "dbb11f5b-30d6-4598-b3f1-44f534204dda"}, "cell_type": "code", "source": "# Get the guid for the space\nspaces_details = client.spaces.get_details()\n\ntag_value = \"dsx-project.\" + project_id\nmySpaces_details = next(item for item in spaces_details['resources']\n                    if 'tags' in item['entity'] and item['entity']['tags'][0]['value'] == tag_value\n                       )\n\nspace_uid = mySpaces_details['metadata']['guid']\nspace_name = mySpaces_details['entity']['name']\nspace_href = client.spaces.get_href(mySpaces_detail)\nprint(space_name + \" guid: \" + space_uid)\nclient.set.default_space(space_uid)", "execution_count": null, "outputs": []}, {"metadata": {"id": "2b9b3e18-5c7b-4ebb-bb60-ebc482f89769"}, "cell_type": "markdown", "source": "## List the models\nTo use the client API, we first need to sertup the defult space. This is done in the previous cell.\n\nThe method we use below only lists the information to the output. Other methods allow us to receive the output programmatically.\n\nNote that the only model that is shown is the one that was promoted to the deployment space."}, {"metadata": {"id": "1db1c6dd-4383-4e5c-912b-7f14c1fbe2ae"}, "cell_type": "code", "source": "client.repository.list_models()", "execution_count": null, "outputs": []}, {"metadata": {"id": "f834d8ca-4f93-4882-b494-edeb4777c1a7"}, "cell_type": "markdown", "source": "## List deployments\nThe method we use below only lists the information to the output. Other methods allow us to receive the output programmatically.\n"}, {"metadata": {"id": "27402309-05b6-4a59-89ff-c4492afb8d4e"}, "cell_type": "code", "source": "client.deployments.list()", "execution_count": null, "outputs": []}, {"metadata": {"id": "de945365-e8f4-41ce-b419-0a0af98d1a44"}, "cell_type": "markdown", "source": "## Score using the deployed model\nIn this case, we go through the available models and find the one we want using its name.<br/>\nWe can also get more details.\n\nIf there were multiple deployed models, we could find the model by name using the following code:\n```\ndeployments_details = client.deployments.get_details()\ndeployed_details = next(item for item in deployments_details['resources']\n                    if item['entity'][\"name\"] == \"AutoAI Churn Deployment\")\ndeployed_uid = deployed_details['metadata']['guid']\n```\n\nSince we currently only have one deployed model, we can simply take the first one."}, {"metadata": {"id": "95fc15b7-2706-4102-9736-146badb4e864"}, "cell_type": "code", "source": "deployments_details = client.deployments.get_details()\ndeployed_details = deployments_details['resources'][0]\n                    \ndeployed_uid = deployed_detail['metadata']['guid']\ndeployed_name = deployed_detail['entity']['name']\nprint(\"Deployment name: \" + deployed_name + \", uid: \" + deployed_uid)", "execution_count": null, "outputs": []}, {"metadata": {"id": "4e0bedf1-bee7-4604-a0f4-b43092851bb6"}, "cell_type": "code", "source": "# Get the related model details\nmodel_details = client.repository.get_model_details(deployed_details['entity']['asset']['href'].split('/')[-1] )\n\n# Input field names \nfieldnames = [x['name'] for x in model_details['entity']['schemas']['input'][0]['fields']] \n\noutput = \"[\"\nfor field in fildnames:\n    output += '\"' + field + '\",'\noutput += ']'\noutput", "execution_count": null, "outputs": []}, {"metadata": {"id": "45982411-ec1c-456f-805b-4db04264fa86"}, "cell_type": "code", "source": "# Execute the model\nscorring_payload = { client.deployments.ScoringMetaNames.INPUT_DATA:\n                      [{\n                         'fields': fieldnames,\n                         'values': [[1,'F','S',1.0,38000.0,'N',24.393333,23.56,0.0,206.08,0.0,'CC','Budget','Intnl_discount',229.64,3.0],\n                                    [6,'M','M',2.0,29616.0,'N',49.426667,29.78,0.0,45.5,0.0,  'CH','FreeLocal','Standard',75.29,2.0]\n                                   ]\n                        }]\n                      }\npredictions = client.deployments.score(deployed_uid, scoring_payload)\n\nfor prediction in predictions['predictions'] :\n    for result in prediction['values'] :\n        print('Prediction: {}, probability: [{}]'.format(result[0], result[1]))", "execution_count": null, "outputs": []}, {"metadata": {"id": "7b04863a-77f3-429d-b62e-19f2a879f435"}, "cell_type": "markdown", "source": "## Deploy house pricing model\nWe have a saved model that we need to promote to the deployment space and then deploy. Then we can use it to score records.\n\nWe need to set the default project to see the model we want promote and deploy."}, {"metadata": {"id": "23963d00-38e6-4d0d-b0c0-d2dfaa05d7e8"}, "cell_type": "code", "source": "client.set.default_project(project_id)\n\nmodel_details = next(item for item in client.repository.get_model_details()['resources']\n                    if item['entity'][\"name\"] == \"AutoAI Price Estimate Model\")\nmodel_uid = client.repository.get_model_uid(model_details)\nprint(\"Model name: \" + model_details['entity']['name'] + \", uid: \" + model_uid)", "execution_count": null, "outputs": []}, {"metadata": {"id": "b7186af0-6f32-4d0f-b13e-20156806a91f"}, "cell_type": "markdown", "source": "### Promote using the REST API"}, {"metadata": {"id": "9b876e8f-f979-46cc-9161-841ad952ad88"}, "cell_type": "code", "source": "url = service_instance_url + \"/api/rest/catalogs/assets/\" + model_uid + \"/promote\" \n\nheaders = {\n    'Authorization': \"Bearer \" + accessToken,\n    'Content-Type': \"application/json\"\n}\n\nmetadata = {\n    \"spaceId\": space_uid,\n    \"projectId\": project_id,\n    \"spaceName\": space_name,\n    \"projectName\": project_name,\n    \"assetType\": \"model\",\n    \"mlInstanceGuid\": mlInstanceGuid\n}\n\npayload = json.dumps(metadata, separators=(',', ':'))\npromote_response = requests.post(url, \n                            data=payload,\n                            headers=headers, \n                            verify=False\n                        )\n\n# print(promote_response.json());\npromotedModelHref = promote_response.json()[\"href\"]\n\npromoted_model_response = requests.get(service_instance_url + promotedModelHref,\n                            headers=headers, \n                            verify=False\n                        )\n\n# print(promoted_model_response.json());\npromotedModelGuid = promoted_model_response.json()[\"metadata\"][\"asset_id\"]\npromotedModelHref = promoted_model_response.json()[\"href\"]\npromotedModelName = promoted_model_response.json()['metadata']['name']\n\nprint(promotedModelName + \" guid: \" + promotedModelGuid)", "execution_count": null, "outputs": []}, {"metadata": {"id": "a92aa8ee-af10-45fc-a70a-550f4b79c8c4"}, "cell_type": "markdown", "source": "### Deploy using the REST API"}, {"metadata": {"id": "aff61fd1-3071-41fe-b38a-9426ef7a0a04"}, "cell_type": "code", "source": "url = service_instance_url + \"/v4/deployments\"\ndeployment_name = promotedModelName + '_deployed'\n \nmetadata = {\n    \"name\": deployment_name,\n    \"online\": {},\n    \"space\": { \n        \"href\": space_href\n    },\n    \"asset\": {\n        \"href\": \"/v4/models/\" + promotedModelGuid + \"?space_id=\" + space_uid\n    }\n}\nheaders = {\n    'Authorization': \"Bearer \" + accessToken,\n    'Content-Type': \"application/json\"\n}\npayload = json.dumps(metadata, separators=(',', ':'))\n \ndeploy_response = requests.post(url, \n                            headers=headers, \n                            data=payload,\n                            verify=False\n                  )\ndeployment_details = deploy_response.json()\ndeployment_uid = client.deployments.get_uid(deployment_details)\n# print(json.dumps(deployment_details, indent=4, sort_keys=True))\nprint(\"Deployment uid: \" + deployment_uid)", "execution_count": null, "outputs": []}, {"metadata": {"id": "71756c92-16f5-4355-b584-55c98c373887"}, "cell_type": "markdown", "source": "## Score house pricing\nWe saw earlier that we can score records using the deployment information.\n\nWe can tie the deployment to the model information and use the model information to find out the input and output record formats and other information."}, {"metadata": {"id": "51d37746-b2b8-47a4-b6c0-838e04b2bfe4"}, "cell_type": "code", "source": "# Input field names \n# Use the API to retrieve the field names used in the scoring call\nfieldnames = [x['name'] for x in model_details['entity']['schemas']['input'][0]['fields']] \n', '.join(fieldnames)", "execution_count": null, "outputs": []}, {"metadata": {"id": "c6453e3e-30c6-4ff2-8a1a-7331ba6907b7"}, "cell_type": "code", "source": "# Execute the model\nclient.set.default_space(space_uid)\n\nscoring_payload = { client.deployments.ScoringMetaNames.INPUT_DATA:\n                      [{\n                         'fields': fildnames,\n                         'values': [[0.17004,12.5,7.87,0,0.524,6.004,85.9,6.5921,5,311,15.2,386.71,17.1,18.9],\n                                    [0.22489,12.5,7.87,0,0.524,6.377,94.3,6.3467,5,311,15.2,392.52,20.45,15]\n                                   ]\n                        }]\n                      }\npredictions = client.deployments.score(deployment_uid, scoring_payload)\nprint(\"Predictions: {}\".format([prediction['values'] for prediction in predictions['predictions']]))", "execution_count": null, "outputs": []}, {"metadata": {"id": "213cddec-495f-4f61-9284-405e55ba3a54"}, "cell_type": "markdown", "source": "### Remove the deployment"}, {"metadata": {"id": "fd315d9f-17f6-478a-a9de-85624869a7d5"}, "cell_type": "code", "source": "client.deployments.delete(deployment_id)", "execution_count": null, "outputs": []}, {"metadata": {"id": "b0ad134d-cf0c-42b8-b796-31f0dceb69b5"}, "cell_type": "markdown", "source": "## Create, save, promote and deploy a model"}, {"metadata": {"id": "c41cf69a-76f8-45ac-9562-64e563595a66"}, "cell_type": "markdown", "source": "## Read training data"}, {"metadata": {"id": "46f6fa16-9450-4b18-bbb1-9ef95c576570"}, "cell_type": "code", "source": "import pandas as pd\n\nurl = 'https://github.com/jacquesroy/byte-size-data-science/raw/master/data/customer_churn.csv'\ntelco_df = pd.read_csv(url)\ntelco_df.head()", "execution_count": null, "outputs": []}, {"metadata": {"id": "8f1a06d4-6a71-4af3-8e26-64d16d8e9529"}, "cell_type": "markdown", "source": "## Create a Churn model\nCreate a model and evaluiate it"}, {"metadata": {"id": "5ca88991-5e68-4647-8d4d-e9c98b13b658"}, "cell_type": "code", "source": "from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\n", "execution_count": null, "outputs": []}, {"metadata": {"id": "57b7167e-ef97-4312-a0e8-e0c8be851489"}, "cell_type": "code", "source": "# Prepare pipeline to process categorical data and final processing pipeline\n# We may want to add another preprocessing pipeline to handle numerical null values\ncategorical_features = ['Gender','Status','Car Owner','Paymethod','LocalBilltype','LongDistanceBilltype']\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('cat', categorical_transformer, categorical_features)])\n\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('classifier', DecisionTreeClassifier())])", "execution_count": null, "outputs": []}, {"metadata": {"id": "a8460506-e9a1-4463-894f-f1feaf6b7540"}, "cell_type": "code", "source": "# Split into train and test\nX = telco_df.drop('CHURN', axis=1)\ny = telco_df['CHURN']\n\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n\nmodel = clf.fit(X_train, y_train)\nres_predict = model.predict(X_test)\nprint(\"model score: %.3f\" % clf.score(X_test, y_test))\nprint(classification_report(y_test, res_predict, target_names=[\"False\", \"True\"]))", "execution_count": null, "outputs": []}, {"metadata": {"id": "c420e411-f166-4a84-8751-aa3d3c87c6bd"}, "cell_type": "markdown", "source": "## Saving the model to WML"}, {"metadata": {"id": "35a1d263-ed9b-4313-b2aa-57dabad80e84"}, "cell_type": "code", "source": "# If we want to know the different aatributes that can be set when saving a model\nclient.repository.ModelMetaNames.git()", "execution_count": null, "outputs": []}, {"metadata": {"id": "0b4fc5bb-5c1b-42c1-a97a-18e7a4e7c538"}, "cell_type": "code", "source": "# Checking the sklearn version we are using\nimport sklearn\nsklearn.__version__", "execution_count": null, "outputs": []}, {"metadata": {"id": "65d3e7e9-11af-4479-8978-1dbbc6a95ff7"}, "cell_type": "code", "source": "metadata = {\n  client.repository.ModelMetaNames.NAME: 'Telco Churn Prediction Model',\n  client.repository.ModelMetaNames.TYPE: 'scikit-learn_0.20',\n  client.repository.ModelMetaNames.RUNTIME_UID: 'scikit-learn_0.20-py3'\n}\n# Name the columns\ncols=[\"Gender\", \"Status\", \"Children\", \"Est Income\", \"Car Owner\", \"Age\", \"LongDistance\",\n      \"International\", \"Local\", \"Dropped\", \"Paymethod\", \"LocalBilltype\",\n      \"LongDistanceBilltype\", \"Usage\", \"RatePlan\"]\n      \n\nsaved_model = client.repository.store_model(model=model, meta_props=metadata, \n                                            # training_data=X_train, training_target=y_train, \n                                            feature_names=cols, label_column_names=[\"CHURN\"] )\nsaved_model", "execution_count": null, "outputs": []}, {"metadata": {"id": "ce5d9f5c-09c3-4fbd-9a3c-6a9591371fae"}, "cell_type": "code", "source": "# See that it made it into WML\nclient.repository.list_models()", "execution_count": null, "outputs": []}, {"metadata": {"id": "9392ed00-dfd4-4d40-ad8d-c46e4c04da57"}, "cell_type": "markdown", "source": "## Publish the model"}, {"metadata": {"id": "32b7abde-a974-4e29-a3fb-8d51e55081c4"}, "cell_type": "code", "source": "# Get the model UID\ntelco_model_uid = client.repository.get_model_uid(saved_model)\n\nmeta_props = {\n    client.deployments.ConfigurationMetaNames.NAME: \"Telco Churn Deployment\",\n    client.deployments.ConfigurationMetaNames.ONLINE: {}\n}\n\nchurn_deployment_details = client.deployments.created(telco_model_uid, meta_props)\nchurn_deployment_details", "execution_count": null, "outputs": []}, {"metadata": {"id": "f78946ac-29f1-4255-8109-78ea52889175"}, "cell_type": "code", "source": "# See that it was deployed\nclient.deployments.list()", "execution_count": null, "outputs": []}, {"metadata": {"id": "3668849d-1484-4570-ae6b-20630c28b912"}, "cell_type": "markdown", "source": "## Accessing deployed model"}, {"metadata": {"id": "56d17e5b-647c-4db0-bc21-4436dffb9503"}, "cell_type": "code", "source": "scoring_payload = {client.deployments.ScoringMetaNames.INPUT_DATA: \n                   [{'fields': ['ID','Gender','Status','Children','Est Income','Car Owner',\n                              'Age','LongDistance','International','Local','Dropped',\n                              'Paymethod','LocalBilltype','LongDistanceBilltype',\n                              'Usage','RatePlan'],\n                   'values': [[1,0,0,1.0,38000.0,'N',24.393333,23.56,0.0,206.08,0.0,'CC','Budget','Intnl_discount',229.64,3.0],\n                              [6,1,'M',2.0,29616.0,'N',49.426667,29.78,0.0,45.5,0.0,  'CH','FreeLocal','Standard',75.29,2.0]\n                             ]} ]}\ndeploy_uid = client.deployments.get_uid(churn_deployment_details)\npredictions = client.deployments.score(deploy_uid, scorring_payload)\npredictions", "execution_count": null, "outputs": []}, {"metadata": {"id": "b5838cc9-d821-48bd-a4b0-7658ae6f7464"}, "cell_type": "code", "source": "for prediction in predictions['predictions'][0]['values'] :\n    print(\"Prediction: {}, probability: {}\".format(prediction[0],prediction[1]) )", "execution_count": null, "outputs": []}, {"metadata": {"id": "0c6f8a74-35a0-435d-81a7-71f81abff9c6"}, "cell_type": "markdown", "source": "## Cleanup\nRemove the two models that we deployed in this notebook and the model we saved. This way, we reset the environment to where it was before we stated executing the notebook."}, {"metadata": {"id": "e836ad27-ea32-46e9-9eb7-8b392c3fd2d0"}, "cell_type": "code", "source": "# list the existing deployments to see what we currently have\nclient.deployments.list()", "execution_count": null, "outputs": []}, {"metadata": {"id": "ed3e74fb-6a0a-4a12-9261-e87a5df476b9"}, "cell_type": "code", "source": "# Retrieve the deployment details we want to remove\ndeployments_details = client.deployments.get_details()\nmodel_deployed_details = next(item for item in deployments_details['resources']\n                    if item['entity'][\"name\"] == \"Telco Churn Deployment\")\n\nclient.deployments.delete(client.deployments.get_uid(model_deployed_details))\n\n# See if the deployments were removed\nclient.deployments.list()", "execution_count": null, "outputs": []}, {"metadata": {"id": "55e7de8a-86eb-4441-bbe1-7419a09a2d11"}, "cell_type": "code", "source": "# list the models currently in our WML service\nclient.repository.list_models()", "execution_count": null, "outputs": []}, {"metadata": {"id": "177557b9-9c84-4942-aeb1-37ca3b8aa7cb"}, "cell_type": "code", "source": "# We still have the saved_model variable that includes the model details.\nclient.repository.delete(saved_model['metadata']['guid'])\nclient.repository.list_models()", "execution_count": null, "outputs": []}, {"metadata": {"id": "a1a9ec3a-0e21-41da-a795-15e163588847"}, "cell_type": "markdown", "source": "## Other Artifacts\nWe already saw models and deployments in details. We also just covered runtimes. There are other artifacts you should be aware of\n- **runtimes**: List available runtimes\n- **spaces**: WML includes one default space, we can define additional spaces so we can divide our artifacts more logically and add access control to them. \n- **function and libraries**: You can create functions that can be added to the environment and used in modeling\n- **pipelines**: \n- **trainings**:\n- **experiments**:\n\n"}, {"metadata": {"id": "e8728329-6cab-4277-876e-f242e343f4b9"}, "cell_type": "code", "source": "# List runtimes\nclient.runtimes.list()", "execution_count": null, "outputs": []}, {"metadata": {"id": "e71a2f3b-384b-484a-be1d-da1f1fc88127"}, "cell_type": "code", "source": "# List spaces\nclient.repository.list_spaces()", "execution_count": null, "outputs": []}, {"metadata": {"id": "9b77a9ff-fba1-49cd-aebd-bbdd646cf138"}, "cell_type": "code", "source": "# List functions\nclient.repository.list_functions()", "execution_count": null, "outputs": []}, {"metadata": {"id": "6b070ec4-91d4-4ce2-9974-274edd9901c5"}, "cell_type": "code", "source": "# List pipelines\n# The list is not empty since AutoAI used WML to train models\nclient.repository.list_pipelines()", "execution_count": null, "outputs": []}, {"metadata": {"id": "ade76c98-149f-491f-8d93-86150b6e24b1"}, "cell_type": "code", "source": "# List trainings\n# This reflects the AutoAI model training\nclient.training.list()", "execution_count": null, "outputs": []}, {"metadata": {"id": "51808b52-5b2b-4687-9db2-1f2eca6a6a8c"}, "cell_type": "code", "source": "# List experiments\nclient.repository.list_experiments()", "execution_count": null, "outputs": []}, {"metadata": {"id": "34ffc0c0-702a-4e91-923e-c50cc673850e"}, "cell_type": "markdown", "source": "## WML Metadata\nWe can find out what metadata is available using the WML Client API. The following methods print out the metadata\n- `client.repository.ModelMetaNames.show()`\n- `client.repository.ExperimentMetaNames.show()`\n- `client.repository.FunctionMetaNames.show()`\n- `client.repository.PipelineMetaNames.show()`\n- `client.repository.SpacesMetaNames.show()`\n"}, {"metadata": {"id": "af22c32a-bf67-4a70-99a8-952bb748e8f7"}, "cell_type": "code", "source": "# Example: pipeline metadata\nclient.repository.ModelMetaNames.show()", "execution_count": null, "outputs": []}, {"metadata": {"id": "d34ef2d3-f6eb-4f2d-bac9-4d66b12afb77"}, "cell_type": "markdown", "source": "# Conclusion\nWML facilitate the creating, sharing and running of models. Tools like AutoAI and Modeler Flows that use WML speed-up the development of machine learning models. Since WML is used through a freely available API, it can be used directly through programming interfaces such as a notebook or used to integrate it in other tools developped using languages like Java and Python.\n\nThere is also a REST API available that allows any application to score data with a deployed model."}, {"metadata": {"id": "8fbccd0e-2e45-454d-8f29-226920dbbe25"}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}